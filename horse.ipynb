{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame Shape: (58347, 75)\n",
      "        Date Country          Track Going        Racetype Distance  Class  \\\n",
      "0  6/24/2020      GB       HAMILTON   GTS          Maiden       6f    5.0   \n",
      "1  8/23/2020     IRE           NAAS   SFT    Unclassified       6f    NaN   \n",
      "2   9/9/2020      GB  WOLVERHAMPTON   STD          Maiden       6f    5.0   \n",
      "3  6/20/2021      GB     PONTEFRACT   GTF  Other Handicap       6f    3.0   \n",
      "4   7/8/2021      GB      NEWMARKET   GTF  Other Handicap       6f    2.0   \n",
      "\n",
      "    Time  Stall      Horse  ...  Tick Drop    10 B2L    25 B2L    50 B2L  \\\n",
      "0  14:20    5.0  Abduction  ...       10.0    £3.43   (£10.00)  (£10.00)   \n",
      "1  15:55    3.0  Abduction  ...       12.0    £4.21   (£10.00)  (£10.00)   \n",
      "2  17:45    4.0  Abduction  ...      104.0    £0.78     £1.66     £3.51    \n",
      "3  17:25    7.0  Abduction  ...      110.0    £2.45     £8.02    £18.20    \n",
      "4  15:00   11.0  Abduction  ...        0.0  (£10.00)  (£10.00)  (£10.00)   \n",
      "\n",
      "  10 B2L To Date  25 B2L To Date  50 B2L To Date    OR  Headgear  \\\n",
      "0         £0.00           £0.00           £0.00    0.0       NaN   \n",
      "1         £3.43         (£10.00)        (£10.00)   0.0       NaN   \n",
      "2         £7.64         (£20.00)        (£20.00)   0.0       NaN   \n",
      "3         £8.42         (£18.34)        (£16.49)  84.0       NaN   \n",
      "4        £10.87         (£10.32)          £1.71   86.0       NaN   \n",
      "\n",
      "                  Todays Race  \n",
      "0  DONCASTER / 26/10/24/17:00  \n",
      "1  DONCASTER / 26/10/24/17:00  \n",
      "2  DONCASTER / 26/10/24/17:00  \n",
      "3  DONCASTER / 26/10/24/17:00  \n",
      "4  DONCASTER / 26/10/24/17:00  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/0x9ylhq57vq55_ssc_tyqhc00000gn/T/ipykernel_29853/2064366698.py:16: DtypeWarning: Columns (21,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path containing the CSV files\n",
    "folder_path = \"/Users/rishabh/Downloads/Daily01112024,Daily02112024,Daily03112024\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through the CSV files and load them into DataFrames\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print the shape and a preview of the combined DataFrame\n",
    "print(\"Combined DataFrame Shape:\", df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Track</th>\n",
       "      <th>Going</th>\n",
       "      <th>Racetype</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time</th>\n",
       "      <th>Stall</th>\n",
       "      <th>Horse</th>\n",
       "      <th>...</th>\n",
       "      <th>Tick Drop</th>\n",
       "      <th>10 B2L</th>\n",
       "      <th>25 B2L</th>\n",
       "      <th>50 B2L</th>\n",
       "      <th>10 B2L To Date</th>\n",
       "      <th>25 B2L To Date</th>\n",
       "      <th>50 B2L To Date</th>\n",
       "      <th>OR</th>\n",
       "      <th>Headgear</th>\n",
       "      <th>Todays Race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/24/2020</td>\n",
       "      <td>GB</td>\n",
       "      <td>HAMILTON</td>\n",
       "      <td>GTS</td>\n",
       "      <td>Maiden</td>\n",
       "      <td>6f</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14:20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>£3.43</td>\n",
       "      <td>(£10.00)</td>\n",
       "      <td>(£10.00)</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>£0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DONCASTER / 26/10/24/17:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Country     Track Going Racetype Distance  Class   Time  Stall  \\\n",
       "0  6/24/2020      GB  HAMILTON   GTS   Maiden       6f    5.0  14:20    5.0   \n",
       "\n",
       "       Horse  ...  Tick Drop  10 B2L    25 B2L    50 B2L 10 B2L To Date  \\\n",
       "0  Abduction  ...       10.0  £3.43   (£10.00)  (£10.00)         £0.00    \n",
       "\n",
       "   25 B2L To Date  50 B2L To Date   OR  Headgear                 Todays Race  \n",
       "0          £0.00           £0.00   0.0       NaN  DONCASTER / 26/10/24/17:00  \n",
       "\n",
       "[1 rows x 75 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Place']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in df.columns if \"Place\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Country', 'Track', 'Going', 'Racetype', 'Distance', 'Class',\n",
       "       'Time', 'Stall', 'Horse', 'Age', 'Pace', 'Weight', 'Jockey', 'Trainer',\n",
       "       'SP Fav', 'Industry SP', 'Betfair SP', 'IP Min', 'IP Max', 'Pred ISP',\n",
       "       'Place', 'Winning Distance', 'Runners', 'Tick Drop IR', 'Tick Incr IR',\n",
       "       '% SP Drop', '% SP Incr', 'Runs last 18 mo', 'LTO5 % SP Drop',\n",
       "       'LTO4 % SP Drop', 'LTO3 % SP Drop', 'LTO2 % SP Drop', 'LTO % SP Drop',\n",
       "       'LTO5 IPL', 'LTO4 IPL', 'LTO3 IPL', 'LTO2 IPL', 'LTO IPL', 'Wins L5',\n",
       "       'Avg % SP Drop L5', 'Avg % SP Drop last 18 mo', 'RBD Rating',\n",
       "       'RBD Rank', 'Prev Races', 'Days Since LTO', 'Course Winner',\n",
       "       'Distance Winner', 'Cla diff since LTO', 'OR diff since LTO',\n",
       "       'Crs Wins', 'Dist Wins', 'Class Wins', 'Going Wins', 'Dist (F)',\n",
       "       'Up in Trip', 'WGT (Lbs)', 'WGT diff since LTO', 'Tear Weight',\n",
       "       'Race Rating', 'DOB %', 'DOB P/L £1', 'PRB', 'PRB To Date', 'LTO Pos',\n",
       "       'Tick Drop', '10 B2L', '25 B2L', '50 B2L', '10 B2L To Date',\n",
       "       '25 B2L To Date', '50 B2L To Date', 'OR', 'Headgear', 'Todays Race'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN or empty values:\n",
      "['Going', 'Class', 'Stall', 'Pace', 'Jockey', 'Trainer', 'Betfair SP', 'IP Min', 'IP Max', 'Place', 'Winning Distance', 'Tick Drop IR', 'Tick Incr IR', '% SP Drop', '% SP Incr', 'LTO5 % SP Drop', 'LTO4 % SP Drop', 'LTO3 % SP Drop', 'LTO2 % SP Drop', 'LTO % SP Drop', 'LTO5 IPL', 'LTO4 IPL', 'LTO3 IPL', 'LTO2 IPL', 'LTO IPL', 'Avg % SP Drop L5', 'Avg % SP Drop last 18 mo', 'RBD Rating', 'RBD Rank', 'Days Since LTO', 'Cla diff since LTO', 'OR diff since LTO', 'Up in Trip', 'WGT diff since LTO', 'Tear Weight', 'Race Rating', 'DOB %', 'PRB', 'PRB To Date', 'LTO Pos', 'Tick Drop', '10 B2L', '25 B2L', '50 B2L', 'OR', 'Headgear']\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with NaN or empty values\n",
    "columns_with_nan = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "print(\"Columns with NaN or empty values:\")\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: ['Stall', 'Betfair SP', 'IP Min', 'IP Max', 'Tick Drop IR', '% SP Drop', '% SP Incr', 'RBD Rating', 'RBD Rank', 'Tear Weight', 'Race Rating', 'DOB %', 'PRB', 'PRB To Date', 'Tick Drop', '10 B2L', '25 B2L', '50 B2L', '10 B2L To Date', '25 B2L To Date', '50 B2L To Date', 'Todays Race', 'DOB P/L £1']\n",
      "\n",
      "Remaining missing values: Date                        0\n",
      "Country                     0\n",
      "Track                       0\n",
      "Going                       0\n",
      "Racetype                    0\n",
      "Distance                    0\n",
      "Class                       0\n",
      "Time                        0\n",
      "Horse                       0\n",
      "Age                         0\n",
      "Pace                        0\n",
      "Weight                      0\n",
      "Jockey                      0\n",
      "Trainer                     0\n",
      "SP Fav                      0\n",
      "Industry SP                 0\n",
      "Pred ISP                    0\n",
      "Place                       0\n",
      "Winning Distance            0\n",
      "Runners                     0\n",
      "Tick Incr IR                0\n",
      "Runs last 18 mo             0\n",
      "LTO5 % SP Drop              0\n",
      "LTO4 % SP Drop              0\n",
      "LTO3 % SP Drop              0\n",
      "LTO2 % SP Drop              0\n",
      "LTO % SP Drop               0\n",
      "LTO5 IPL                    0\n",
      "LTO4 IPL                    0\n",
      "LTO3 IPL                    0\n",
      "LTO2 IPL                    0\n",
      "LTO IPL                     0\n",
      "Wins L5                     0\n",
      "Avg % SP Drop L5            0\n",
      "Avg % SP Drop last 18 mo    0\n",
      "Prev Races                  0\n",
      "Days Since LTO              0\n",
      "Course Winner               0\n",
      "Distance Winner             0\n",
      "Cla diff since LTO          0\n",
      "OR diff since LTO           0\n",
      "Crs Wins                    0\n",
      "Dist Wins                   0\n",
      "Class Wins                  0\n",
      "Going Wins                  0\n",
      "Dist (F)                    0\n",
      "Up in Trip                  0\n",
      "WGT (Lbs)                   0\n",
      "WGT diff since LTO          0\n",
      "LTO Pos                     0\n",
      "OR                          0\n",
      "Headgear                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Removal and Imputation\n",
    "\n",
    "# List of columns to remove based on the analysis above\n",
    "columns_to_remove = [\n",
    "    'Stall', 'Betfair SP', 'IP Min', 'IP Max'\n",
    "    , 'Tick Drop IR', '% SP Drop', '% SP Incr',\n",
    "    'RBD Rating', 'RBD Rank',\n",
    "    'Tear Weight', 'Race Rating', 'DOB %', 'PRB', 'PRB To Date', 'Tick Drop', \n",
    "    '10 B2L', '25 B2L', '50 B2L',\"10 B2L To Date\", \"25 B2L To Date\", \"50 B2L To Date\", \n",
    "    \"Todays Race\", \"DOB P/L £1\"\n",
    "]\n",
    "\n",
    "# Remove the sparse columns\n",
    "df_cleaned = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Impute missing values for numerical columns\n",
    "numerical_columns = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_cleaned[numerical_columns] = df_cleaned[numerical_columns].fillna(df_cleaned[numerical_columns].median())\n",
    "\n",
    "# Impute missing values for categorical columns (fill with the mode)\n",
    "categorical_columns = df_cleaned.select_dtypes(include=['object']).columns\n",
    "df_cleaned[categorical_columns] = df_cleaned[categorical_columns].fillna(df_cleaned[categorical_columns].mode().iloc[0])\n",
    "\n",
    "# Print the columns removed\n",
    "print(\"Removed columns:\", columns_to_remove)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "print(\"\\nRemaining missing values:\", df_cleaned.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58347 entries, 0 to 58346\n",
      "Data columns (total 52 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Date                      58347 non-null  object \n",
      " 1   Country                   58347 non-null  object \n",
      " 2   Track                     58347 non-null  object \n",
      " 3   Going                     58347 non-null  object \n",
      " 4   Racetype                  58347 non-null  object \n",
      " 5   Distance                  58347 non-null  object \n",
      " 6   Class                     58347 non-null  float64\n",
      " 7   Time                      58347 non-null  object \n",
      " 8   Horse                     58347 non-null  object \n",
      " 9   Age                       58347 non-null  int64  \n",
      " 10  Pace                      58347 non-null  float64\n",
      " 11  Weight                    58347 non-null  object \n",
      " 12  Jockey                    58347 non-null  object \n",
      " 13  Trainer                   58347 non-null  object \n",
      " 14  SP Fav                    58347 non-null  int64  \n",
      " 15  Industry SP               58347 non-null  float64\n",
      " 16  Pred ISP                  58347 non-null  float64\n",
      " 17  Place                     58347 non-null  object \n",
      " 18  Winning Distance          58347 non-null  object \n",
      " 19  Runners                   58347 non-null  int64  \n",
      " 20  Tick Incr IR              58347 non-null  object \n",
      " 21  Runs last 18 mo           58347 non-null  int64  \n",
      " 22  LTO5 % SP Drop            58347 non-null  float64\n",
      " 23  LTO4 % SP Drop            58347 non-null  float64\n",
      " 24  LTO3 % SP Drop            58347 non-null  float64\n",
      " 25  LTO2 % SP Drop            58347 non-null  float64\n",
      " 26  LTO % SP Drop             58347 non-null  float64\n",
      " 27  LTO5 IPL                  58347 non-null  float64\n",
      " 28  LTO4 IPL                  58347 non-null  float64\n",
      " 29  LTO3 IPL                  58347 non-null  float64\n",
      " 30  LTO2 IPL                  58347 non-null  float64\n",
      " 31  LTO IPL                   58347 non-null  float64\n",
      " 32  Wins L5                   58347 non-null  int64  \n",
      " 33  Avg % SP Drop L5          58347 non-null  float64\n",
      " 34  Avg % SP Drop last 18 mo  58347 non-null  float64\n",
      " 35  Prev Races                58347 non-null  int64  \n",
      " 36  Days Since LTO            58347 non-null  float64\n",
      " 37  Course Winner             58347 non-null  object \n",
      " 38  Distance Winner           58347 non-null  object \n",
      " 39  Cla diff since LTO        58347 non-null  float64\n",
      " 40  OR diff since LTO         58347 non-null  float64\n",
      " 41  Crs Wins                  58347 non-null  int64  \n",
      " 42  Dist Wins                 58347 non-null  int64  \n",
      " 43  Class Wins                58347 non-null  int64  \n",
      " 44  Going Wins                58347 non-null  int64  \n",
      " 45  Dist (F)                  58347 non-null  int64  \n",
      " 46  Up in Trip                58347 non-null  object \n",
      " 47  WGT (Lbs)                 58347 non-null  int64  \n",
      " 48  WGT diff since LTO        58347 non-null  float64\n",
      " 49  LTO Pos                   58347 non-null  object \n",
      " 50  OR                        58347 non-null  float64\n",
      " 51  Headgear                  58347 non-null  object \n",
      "dtypes: float64(21), int64(12), object(19)\n",
      "memory usage: 23.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/0x9ylhq57vq55_ssc_tyqhc00000gn/T/ipykernel_29853/143837492.py:1: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Track</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Jockey</th>\n",
       "      <th>Racetype</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31265</th>\n",
       "      <td>1</td>\n",
       "      <td>SOUTHWELL</td>\n",
       "      <td>A Fine Claret</td>\n",
       "      <td>Pierre-Louis Jamin</td>\n",
       "      <td>Nursery</td>\n",
       "      <td>17:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31312</th>\n",
       "      <td>1</td>\n",
       "      <td>WOLVERHAMPTON</td>\n",
       "      <td>A Pint Of Bear</td>\n",
       "      <td>Joey Haynes</td>\n",
       "      <td>Other Handicap</td>\n",
       "      <td>18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31314</th>\n",
       "      <td>1</td>\n",
       "      <td>KEMPTON</td>\n",
       "      <td>Africa Charm</td>\n",
       "      <td>Neil Callan</td>\n",
       "      <td>Maiden</td>\n",
       "      <td>13:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31345</th>\n",
       "      <td>1</td>\n",
       "      <td>PLUMPTON</td>\n",
       "      <td>Aggagio</td>\n",
       "      <td>Caoilin Quinn</td>\n",
       "      <td>Handicap Hurdle</td>\n",
       "      <td>15:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31362</th>\n",
       "      <td>1</td>\n",
       "      <td>KEMPTON</td>\n",
       "      <td>Aimeric</td>\n",
       "      <td>Clifford Lee</td>\n",
       "      <td>Listed</td>\n",
       "      <td>14:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Place          Track           Horse              Jockey  \\\n",
       "31265     1      SOUTHWELL   A Fine Claret  Pierre-Louis Jamin   \n",
       "31312     1  WOLVERHAMPTON  A Pint Of Bear         Joey Haynes   \n",
       "31314     1        KEMPTON    Africa Charm         Neil Callan   \n",
       "31345     1       PLUMPTON         Aggagio       Caoilin Quinn   \n",
       "31362     1        KEMPTON         Aimeric        Clifford Lee   \n",
       "\n",
       "              Racetype   Time  \n",
       "31265          Nursery  17:45  \n",
       "31312   Other Handicap  18:00  \n",
       "31314           Maiden  13:20  \n",
       "31345  Handicap Hurdle  15:40  \n",
       "31362           Listed  14:20  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "df_aux = df_cleaned[df_cleaned['Date'] == '2024-11-04'][['Place', 'Track', 'Horse', 'Jockey', 'Racetype', 'Time']]\n",
    "df_aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded DataFrame Shape: (58347, 230)\n",
      "Sample DataFrame:\n",
      "         Date  Class   Time  Horse  Age  Pace Weight  Jockey  Trainer  SP Fav  \\\n",
      "0 2020-06-24    5.0  14:20     11    2   0.0    9-5    1214      700       4   \n",
      "\n",
      "   ...  Distance_4m½f  Distance_5f Distance_5½f Distance_6f  Distance_6½f  \\\n",
      "0  ...          False        False        False        True         False   \n",
      "\n",
      "  Distance_7f  Distance_7½f  Course Winner_YES  Distance Winner_YES  \\\n",
      "0       False         False              False                False   \n",
      "\n",
      "   Up in Trip_YES  \n",
      "0           False  \n",
      "\n",
      "[1 rows x 230 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of categorical columns (including new features)\n",
    "categorical_columns = [\n",
    "    \"Country\", \"Track\", \"Going\", \"Racetype\", \"Distance\",\n",
    "    \"Horse\", \"Jockey\", \"Trainer\", \"Place\",\n",
    "    \"Course Winner\", \"Distance Winner\", \"Up in Trip\", \n",
    "    \"Headgear\", \"LTO Pos\", \n",
    "]\n",
    "\n",
    "# Specify high cardinality columns for Label Encoding\n",
    "label_encode_columns = [\n",
    "    \"Horse\", \"Jockey\", \"Trainer\", \n",
    "    \"Headgear\", \n",
    "]\n",
    "\n",
    "# Handle missing values and ensure uniform data types for label encoding\n",
    "df_cleaned[label_encode_columns] = df_cleaned[label_encode_columns].fillna(\"Missing\").astype(str)\n",
    "\n",
    "# Apply Label Encoding\n",
    "label_encoders = {}\n",
    "for col in label_encode_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    label_encoders[col] = le  # Save encoder for future decoding if needed\n",
    "\n",
    "# Specify remaining columns for One-Hot Encoding\n",
    "one_hot_encode_columns = [\n",
    "    \"Country\", \"Track\", \"Going\", \"Racetype\", \"Distance\",\n",
    "    \"Course Winner\", \"Distance Winner\", \"Up in Trip\"\n",
    "]\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=one_hot_encode_columns, drop_first=True)\n",
    "\n",
    "# Print resulting DataFrame structure\n",
    "print(\"Encoded DataFrame Shape:\", df_cleaned.shape)\n",
    "print(\"Sample DataFrame:\\n\", df_cleaned.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Jockey</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>SP Fav</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance_4m½f</th>\n",
       "      <th>Distance_5f</th>\n",
       "      <th>Distance_5½f</th>\n",
       "      <th>Distance_6f</th>\n",
       "      <th>Distance_6½f</th>\n",
       "      <th>Distance_7f</th>\n",
       "      <th>Distance_7½f</th>\n",
       "      <th>Course Winner_YES</th>\n",
       "      <th>Distance Winner_YES</th>\n",
       "      <th>Up in Trip_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14:20</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9-5</td>\n",
       "      <td>1214</td>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Class   Time  Horse  Age  Pace Weight  Jockey  Trainer  SP Fav  \\\n",
       "0 2020-06-24    5.0  14:20     11    2   0.0    9-5    1214      700       4   \n",
       "\n",
       "   ...  Distance_4m½f  Distance_5f Distance_5½f Distance_6f  Distance_6½f  \\\n",
       "0  ...          False        False        False        True         False   \n",
       "\n",
       "  Distance_7f  Distance_7½f  Course Winner_YES  Distance Winner_YES  \\\n",
       "0       False         False              False                False   \n",
       "\n",
       "   Up in Trip_YES  \n",
       "0           False  \n",
       "\n",
       "[1 rows x 230 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58347, 227)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = ['Time','Weight','Tick Incr IR']\n",
    "\n",
    "df_cleaned= df_cleaned.drop(columns=l)\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Class', 'Horse', 'Age', 'Pace', 'Jockey', 'Trainer', 'SP Fav', 'Industry SP', 'Pred ISP', 'Place', 'Winning Distance', 'Runners', 'Runs last 18 mo', 'LTO5 % SP Drop', 'LTO4 % SP Drop', 'LTO3 % SP Drop', 'LTO2 % SP Drop', 'LTO % SP Drop', 'LTO5 IPL', 'LTO4 IPL', 'LTO3 IPL', 'LTO2 IPL', 'LTO IPL', 'Wins L5', 'Avg % SP Drop L5', 'Avg % SP Drop last 18 mo', 'Prev Races', 'Days Since LTO', 'Cla diff since LTO', 'OR diff since LTO', 'Crs Wins', 'Dist Wins', 'Class Wins', 'Going Wins', 'Dist (F)', 'WGT (Lbs)', 'WGT diff since LTO', 'LTO Pos', 'OR', 'Headgear', 'Country_IRE', 'Track_ASCOT', 'Track_AYR', 'Track_BALLINROBE', 'Track_BANGOR-ON-DEE', 'Track_BATH', 'Track_BELLEWSTOWN', 'Track_BEVERLEY', 'Track_BRIGHTON', 'Track_CARLISLE', 'Track_CARTMEL', 'Track_CATTERICK', 'Track_CHELMSFORD CITY', 'Track_CHELTENHAM', 'Track_CHEPSTOW', 'Track_CHESTER', 'Track_CLONMEL', 'Track_CORK', 'Track_CURRAGH', 'Track_DONCASTER', 'Track_DOWN ROYAL', 'Track_DOWNPATRICK', 'Track_DUNDALK', 'Track_EPSOM', 'Track_EXETER', 'Track_FAIRYHOUSE', 'Track_FAKENHAM', 'Track_FFOS LAS', 'Track_FONTWELL', 'Track_GALWAY', 'Track_GOODWOOD', 'Track_GOWRAN PARK', 'Track_HAMILTON', 'Track_HAYDOCK', 'Track_HEREFORD', 'Track_HEXHAM', 'Track_HUNTINGDON', 'Track_KELSO', 'Track_KEMPTON', 'Track_KILBEGGAN', 'Track_KILLARNEY', 'Track_LAYTOWN', 'Track_LEICESTER', 'Track_LEOPARDSTOWN', 'Track_LIMERICK', 'Track_LINGFIELD', 'Track_LISTOWEL', 'Track_LUDLOW', 'Track_MARKET RASEN', 'Track_MUSSELBURGH', 'Track_NAAS', 'Track_NAVAN', 'Track_NEWBURY', 'Track_NEWCASTLE', 'Track_NEWMARKET', 'Track_NEWTON ABBOT', 'Track_NOTTINGHAM', 'Track_PERTH', 'Track_PLUMPTON', 'Track_PONTEFRACT', 'Track_PUNCHESTOWN', 'Track_REDCAR', 'Track_RIPON', 'Track_ROSCOMMON', 'Track_SALISBURY', 'Track_SANDOWN', 'Track_SEDGEFIELD', 'Track_SLIGO', 'Track_SOUTHWELL', 'Track_STRATFORD', 'Track_TAUNTON', 'Track_THIRSK', 'Track_THURLES', 'Track_TIPPERARY', 'Track_TOWCESTER', 'Track_TRAMORE', 'Track_UTTOXETER', 'Track_WARWICK', 'Track_WETHERBY', 'Track_WEXFORD', 'Track_WINCANTON', 'Track_WINDSOR', 'Track_WOLVERHAMPTON', 'Track_WORCESTER', 'Track_YARMOUTH', 'Track_YORK', 'Going_GD', 'Going_GTF', 'Going_GTS', 'Going_GTY', 'Going_HTS', 'Going_HVY', 'Going_SFT', 'Going_SLW', 'Going_STD', 'Going_STFA', 'Going_STSL', 'Going_YLD', 'Going_YTS', 'Racetype_Claiming Stakes', 'Racetype_Classified Stakes', 'Racetype_Conditions Stakes', 'Racetype_Group 1', 'Racetype_Group 2', 'Racetype_Group 3', 'Racetype_Handicap Chase', 'Racetype_Handicap Hurdle', 'Racetype_Hunters Chase', 'Racetype_Listed', 'Racetype_Maiden', 'Racetype_NH Flat', 'Racetype_Novice Chase', 'Racetype_Novice Hcap Chase', 'Racetype_Novice Hcap Hurdle', 'Racetype_Novice Hurdle', 'Racetype_Novice Stakes', 'Racetype_Nursery', 'Racetype_Other Chase', 'Racetype_Other Handicap', 'Racetype_Other Hurdle', 'Racetype_Selling Handicap', 'Racetype_Selling Hurdle', 'Racetype_Selling Stakes', 'Racetype_Unclassified', 'Distance_1m1f', 'Distance_1m1½f', 'Distance_1m2f', 'Distance_1m2½f', 'Distance_1m3f', 'Distance_1m3½f', 'Distance_1m4f', 'Distance_1m4½f', 'Distance_1m5f', 'Distance_1m5½f', 'Distance_1m6f', 'Distance_1m6½f', 'Distance_1m7f', 'Distance_1m7½f', 'Distance_1m½f', 'Distance_2m', 'Distance_2m1f', 'Distance_2m1½f', 'Distance_2m2f', 'Distance_2m2½f', 'Distance_2m3f', 'Distance_2m3½f', 'Distance_2m4f', 'Distance_2m4½f', 'Distance_2m5f', 'Distance_2m5½f', 'Distance_2m6f', 'Distance_2m6½f', 'Distance_2m7f', 'Distance_2m7½f', 'Distance_2m½f', 'Distance_3m', 'Distance_3m1f', 'Distance_3m1½f', 'Distance_3m2f', 'Distance_3m2½f', 'Distance_3m3f', 'Distance_3m3½f', 'Distance_3m4f', 'Distance_3m4½f', 'Distance_3m5f', 'Distance_3m5½f', 'Distance_3m6f', 'Distance_3m6½f', 'Distance_3m7f', 'Distance_3m7½f', 'Distance_3m½f', 'Distance_4m', 'Distance_4m1f', 'Distance_4m1½f', 'Distance_4m2f', 'Distance_4m2½f', 'Distance_4m½f', 'Distance_5f', 'Distance_5½f', 'Distance_6f', 'Distance_6½f', 'Distance_7f', 'Distance_7½f', 'Course Winner_YES', 'Distance Winner_YES', 'Up in Trip_YES']\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Place', 'Winning Distance', 'LTO Pos'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get all columns of object type\n",
    "object_columns = df_cleaned.columns[df_cleaned.dtypes == 'object']\n",
    "\n",
    "# Print the list of object-type columns\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Place':\n",
      "['2' '5' '1' '12' '23' '11' '6' '14' '8' '3' '15' '7' '21' '4' '10' '19'\n",
      " '9' '16' '20' '13' '18' '27' '24' 'PU' 'F' '28' 'UR' '17' 'DSQ' '26' 'BD'\n",
      " 'RO' '22' '25' '29' '31' 'SU' 'RR' '30' 'REF' 'CO' 3.0 8.0 1.0 13.0 7.0\n",
      " 4.0 5.0 9.0]\n",
      "\n",
      "Unique values in 'Winning Distance':\n",
      "['3½' '4¾' '1¾' 'hd' '5' '26' '10' '3¼' '5¼' '10¼' '8¼' '1½' '16' '2'\n",
      " 'shd' '1' '¾' '½' '2¾' '5½' '13¾' '8' '2¼' '17' '1¼' '10¾' '4½' '3¾'\n",
      " '11¼' 'nk' '5¾' '2½' '15¾' '8½' '4¼' 'nse' '6¾' '20½' '32½' '4' '9½'\n",
      " '12¾' '6½' '7' '7½' '11' '13' '9' '3' '9¼' '16½' '11¾' '15½' '21¼' 'snk'\n",
      " 'dht' '19¾' '41½' '12½' '8¾' '10½' '14' '11½' '6' '19½' '23¾' '6¼' '24½'\n",
      " '18' '57¾' '21¾' '15¼' '30¼' '7¾' '12¼' '17¾' '20¼' '9¾' '22¾' '20¾' '43'\n",
      " '44¼' '13½' '38' '26¾' '46¾' '27¾' '29' '19' '24¼' '45' '25½' '57½' '48½'\n",
      " '28' '35' '17½' '37¼' '32¼' '21½' '12' '14¾' '27' '28¾' '36¼' '21' '48'\n",
      " '13¼' '28¼' '32' '27¼' '33¼' '65' '46½' '81¾' '91¾' '28½' '34¼' '20' '7¼'\n",
      " '63¾' '18¼' '26¼' '60¾' '22½' '14½' '40½' '43¼' '14¼' '18¾' '74½' '47¼'\n",
      " '37' '41' '15' '19¼' '27½' '44' '16¾' '24' '16¼' '113¼' '140½' '106¼'\n",
      " '99¼' '109½' '36' '24¾' '92¾' '45½' '50¼' '36½' '60¼' '¼' '29¼' '33½'\n",
      " '35¾' '39¼' '30¾' '23' '31½' '54¼' '53¼' '23¼' '39½' '83' '51' '25¼'\n",
      " '55¼' '98' '80¼' '30' '30½' '23½' '31¾' '34' '32¾' '38¼' '29½' '34½'\n",
      " '36¾' '33¾' '47' '63½' '104¼' '25' '51¾' '38½' '77½' '45¾' '42½' '76'\n",
      " '22¼' '31¼' '52¾' '134¼' '63¼' '29¾' '65¾' '17¼' '33' '49¾' '47¾' '26½'\n",
      " '41¼' '83¾' '37½' '72' '45¼' '64' '41¾' '129' '98½' '76½' '85¼' '88½'\n",
      " '59½' '40' '61¼' '43½' '35¼' '63' '59' '58¾' '22' '55¾' '50' '99¾' '73½'\n",
      " '92' '51¼' '74¼' '61' '73¼' '62¼' '64¼' '48¾' '55½' '18½' '49¼' '78¼'\n",
      " '49' '60' '112¾' '31' '42' '75¼' '0' '48¼' '52¼' '80' '46¼' '67' '86¼'\n",
      " '40¼' '77¾' '81' '34¾' '43¾' '25¾' '52' '54' '40¾' '114¼' '69¼' '38¾'\n",
      " '71¼' '39' '77' '75½' '35½' '70½' '42¼' '73' '58½' '125¼' '59¾' '58¼'\n",
      " '126½' '68½' '123¼' '54¾' '39¾' '44¾' '62' '46' '70' '57' '68¾' '65¼'\n",
      " '44½' '112' '53½' '56¼' '61½' '86¾' '71½' '59¼' '96¾' '92½' '124' '62½'\n",
      " '91' '94¾' '52½' '84½' '80¾' '58' '89' '91¼' '53¾' '79¾' '74¾' '67½'\n",
      " '60½' '88¼' '95½' '147½' '47½' '56¾' '56½' '54½' '64¾' '81¼' '78' '120¼'\n",
      " '57¼' '56' '96' '62¾' '210½' '76¼' '55' '88' '89½' '94¼' '96¼' '37¾'\n",
      " '98¼' '68' '170½' '100½' '42¾' '78¾' '73¾' '132' '70¾' '64½' '90¾' '51½'\n",
      " '117¼' '69½' '66½' '85' '103½' '72¼' '122¼' '84¾' '53' '101¼' '49½' '61¾'\n",
      " '168½' '74' '118' '70¼' '103' '75¾' '66' '144' '97¾' '50¾' '75' '93½'\n",
      " '72¾' '131¼' '95' '197' '97¼' '146¼' '76¾' '131¾' '107' '83½' '95¾' '93¼'\n",
      " '115¼' '86' '116½' '156¾' '111½' '83¼' '86½' '90¼' '116¾' '79½' '72½'\n",
      " '67¼' '68¼' '120½' 'sht-hd' '89¼' '118¾' '95¼' '185¾' '172' '110' '136'\n",
      " '97½' '79¼' '196½' '79' '65½' '143' '85½' '69' '157½' '137¼' '90' '87½'\n",
      " '121¾' '162½' '120¾' '119¾' '98¾' '99' '80½' '102½' '128' '108' '122¾'\n",
      " '113½' '109¼' '82¼' '67¾' '82¾' '140¼' '149½' '82½' '97' '112½' '100¾'\n",
      " '71' '140¾' '50½' '239¾' '117' '71¾' '184' '77¼' '143¼' '131' '81½' '99½'\n",
      " '66¼' '163½' '255¾' '137' '78½' '105' '69¾' '91½' '111¼' '94½' '138¾'\n",
      " '66¾' '113¾' '87' '118½' '109¾' '223¼' '145¾' '100¼' '166½' '101' '172¾'\n",
      " '137¾' '127½' '157¾' '106½' '126¾' '106' '144¾' '116' '169½' '130¾'\n",
      " '121½' '115½' '87¼' '82' '165' '102¾' '122½' '192¼' '119½' 'dist' '119'\n",
      " '116¼' '108½' '105½' '124¼' '96½' '111' '88¾' '114½' '177¼' '186' '104'\n",
      " '92¼' '183½']\n",
      "\n",
      "Unique values in 'LTO Pos':\n",
      "['1' '2' '5' '12' '23' '11' '6' '14' '8' '3' '15' '7' '21' '4' '10' '19'\n",
      " '9' '16' '20' '13' '18' '27' '24' 'PU' 'F' '28' 'UR' '17' 'DSQ' '26' 'BD'\n",
      " 'RO' '22' '25' '29' '31' 'SU' 'RR' '30' 'REF' 'CO' 1 3 8 13 7 4 5 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract unique values for each column\n",
    "columns_to_check = [\"Place\", \"Winning Distance\", \"LTO Pos\"]\n",
    "for col in columns_to_check:\n",
    "    print(f\"Unique values in '{col}':\\n{df_cleaned[col].unique()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Place' after conversion:\n",
      "[-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "\n",
      "Unique values in 'Winning Distance' after conversion:\n",
      "[0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0, 4.25, 4.5, 4.75, 5.0, 5.25, 5.5, 5.75, 6.0, 6.25, 6.5, 6.75, 7.0, 7.25, 7.5, 7.75, 8.0, 8.25, 8.5, 8.75, 9.0, 9.25, 9.5, 9.75, 10.0, 10.25, 10.5, 10.75, 11.0, 11.25, 11.5, 11.75, 12.0, 12.25, 12.5, 12.75, 13.0, 13.25, 13.5, 13.75, 14.0, 14.25, 14.5, 14.75, 15.0, 15.25, 15.5, 15.75, 16.0, 16.25, 16.5, 16.75, 17.0, 17.25, 17.5, 17.75, 18.0, 18.25, 18.5, 18.75, 19.0, 19.25, 19.5, 19.75, 20.0, 20.25, 20.5, 20.75, 21.0, 21.25, 21.5, 21.75, 22.0, 22.25, 22.5, 22.75, 23.0, 23.25, 23.5, 23.75, 24.0, 24.25, 24.5, 24.75, 25.0, 25.25, 25.5, 25.75, 26.0, 26.25, 26.5, 26.75, 27.0, 27.25, 27.5, 27.75, 28.0, 28.25, 28.5, 28.75, 29.0, 29.25, 29.5, 29.75, 30.0, 30.25, 30.5, 30.75, 31.0, 31.25, 31.5, 31.75, 32.0, 32.25, 32.5, 32.75, 33.0, 33.25, 33.5, 33.75, 34.0, 34.25, 34.5, 34.75, 35.0, 35.25, 35.5, 35.75, 36.0, 36.25, 36.5, 36.75, 37.0, 37.25, 37.5, 37.75, 38.0, 38.25, 38.5, 38.75, 39.0, 39.25, 39.5, 39.75, 40.0, 40.25, 40.5, 40.75, 41.0, 41.25, 41.5, 41.75, 42.0, 42.25, 42.5, 42.75, 43.0, 43.25, 43.5, 43.75, 44.0, 44.25, 44.5, 44.75, 45.0, 45.25, 45.5, 45.75, 46.0, 46.25, 46.5, 46.75, 47.0, 47.25, 47.5, 47.75, 48.0, 48.25, 48.5, 48.75, 49.0, 49.25, 49.5, 49.75, 50.0, 50.25, 50.5, 50.75, 51.0, 51.25, 51.5, 51.75, 52.0, 52.25, 52.5, 52.75, 53.0, 53.25, 53.5, 53.75, 54.0, 54.25, 54.5, 54.75, 55.0, 55.25, 55.5, 55.75, 56.0, 56.25, 56.5, 56.75, 57.0, 57.25, 57.5, 57.75, 58.0, 58.25, 58.5, 58.75, 59.0, 59.25, 59.5, 59.75, 60.0, 60.25, 60.5, 60.75, 61.0, 61.25, 61.5, 61.75, 62.0, 62.25, 62.5, 62.75, 63.0, 63.25, 63.5, 63.75, 64.0, 64.25, 64.5, 64.75, 65.0, 65.25, 65.5, 65.75, 66.0, 66.25, 66.5, 66.75, 67.0, 67.25, 67.5, 67.75, 68.0, 68.25, 68.5, 68.75, 69.0, 69.25, 69.5, 69.75, 70.0, 70.25, 70.5, 70.75, 71.0, 71.25, 71.5, 71.75, 72.0, 72.25, 72.5, 72.75, 73.0, 73.25, 73.5, 73.75, 74.0, 74.25, 74.5, 74.75, 75.0, 75.25, 75.5, 75.75, 76.0, 76.25, 76.5, 76.75, 77.0, 77.25, 77.5, 77.75, 78.0, 78.25, 78.5, 78.75, 79.0, 79.25, 79.5, 79.75, 80.0, 80.25, 80.5, 80.75, 81.0, 81.25, 81.5, 81.75, 82.0, 82.25, 82.5, 82.75, 83.0, 83.25, 83.5, 83.75, 84.5, 84.75, 85.0, 85.25, 85.5, 86.0, 86.25, 86.5, 86.75, 87.0, 87.25, 87.5, 88.0, 88.25, 88.5, 88.75, 89.0, 89.25, 89.5, 90.0, 90.25, 90.75, 91.0, 91.25, 91.5, 91.75, 92.0, 92.25, 92.5, 92.75, 93.25, 93.5, 94.25, 94.5, 94.75, 95.0, 95.25, 95.5, 95.75, 96.0, 96.25, 96.5, 96.75, 97.0, 97.25, 97.5, 97.75, 98.0, 98.25, 98.5, 98.75, 99.0, 99.25, 99.5, 99.75, 100.0, 100.25, 100.5, 100.75, 101.0, 101.25, 102.5, 102.75, 103.0, 103.5, 104.0, 104.25, 105.0, 105.5, 106.0, 106.25, 106.5, 107.0, 108.0, 108.5, 109.25, 109.5, 109.75, 110.0, 111.0, 111.25, 111.5, 112.0, 112.5, 112.75, 113.25, 113.5, 113.75, 114.25, 114.5, 115.25, 115.5, 116.0, 116.25, 116.5, 116.75, 117.0, 117.25, 118.0, 118.5, 118.75, 119.0, 119.5, 119.75, 120.25, 120.5, 120.75, 121.5, 121.75, 122.25, 122.5, 122.75, 123.25, 124.0, 124.25, 125.25, 126.5, 126.75, 127.5, 128.0, 129.0, 130.75, 131.0, 131.25, 131.75, 132.0, 134.25, 136.0, 137.0, 137.25, 137.75, 138.75, 140.25, 140.5, 140.75, 143.0, 143.25, 144.0, 144.75, 145.75, 146.25, 147.5, 149.5, 156.75, 157.5, 157.75, 162.5, 163.5, 165.0, 166.5, 168.5, 169.5, 170.5, 172.0, 172.75, 177.25, 183.5, 184.0, 185.75, 186.0, 192.25, 196.5, 197.0, 210.5, 223.25, 239.75, 255.75]\n",
      "\n",
      "Unique values in 'LTO Pos' after conversion:\n",
      "[-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_to_numeric(value):\n",
    "    \"\"\"\n",
    "    Converts the given value to a numeric type (integer or float) if possible.\n",
    "    If conversion is not possible, returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "\n",
    "# Define a mapping for non-numeric terms in Place and LTO Pos\n",
    "place_mapping = {\n",
    "    \"PU\": -1,\n",
    "    \"F\": -2,\n",
    "    \"UR\": -3,\n",
    "    \"DSQ\": -4,\n",
    "    \"BD\": -5,\n",
    "    \"RO\": -6,\n",
    "    \"SU\": -7,\n",
    "    \"RR\": -8,\n",
    "    \"REF\": -9,\n",
    "    \"CO\": -10,\n",
    "}\n",
    "\n",
    "# Define a function to parse winning distances\n",
    "def parse_winning_distance(value):\n",
    "    try:\n",
    "        # Mapping for special terms\n",
    "        special_terms = {\n",
    "            \"hd\": 0.1,\n",
    "            \"nk\": 0.25,\n",
    "            \"shd\": 0.05,\n",
    "            \"nse\": 0.01,\n",
    "            \"dht\": 0,\n",
    "            \"dist\": 100,\n",
    "        }\n",
    "        # Check if value is a special term\n",
    "        if value in special_terms:\n",
    "            return special_terms[value]\n",
    "        # Parse fractions and mixed fractions\n",
    "        match = re.match(r\"(\\d+)?(?:[¼½¾]|\\s\\d+)?[¼½¾]?\", value)\n",
    "        if match:\n",
    "            whole = int(match.group(1)) if match.group(1) else 0\n",
    "            fraction = value[-1]  # Extract the last fraction part\n",
    "            fraction_mapping = {\"¼\": 0.25, \"½\": 0.5, \"¾\": 0.75}\n",
    "            fraction_value = fraction_mapping.get(fraction, 0)\n",
    "            return whole + fraction_value\n",
    "        # Otherwise, convert to float directly\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# Apply transformations to the DataFrame\n",
    "df_cleaned[\"Place\"] = df_cleaned[\"Place\"].replace(place_mapping).apply(parse_to_numeric)\n",
    "df_cleaned[\"LTO Pos\"] = df_cleaned[\"LTO Pos\"].replace(place_mapping).apply(parse_to_numeric)\n",
    "df_cleaned[\"Winning Distance\"] = df_cleaned[\"Winning Distance\"].apply(parse_winning_distance)\n",
    "\n",
    "# Verify unique values after conversion\n",
    "for col in [\"Place\", \"Winning Distance\", \"LTO Pos\"]:\n",
    "    print(f\"Unique values in '{col}' after conversion:\\n{sorted(df_cleaned[col].dropna().unique())}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get all columns of object type\n",
    "object_columns = df_cleaned.columns[df_cleaned.dtypes == 'object']\n",
    "\n",
    "# Print the list of object-type columns\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Class, Horse, Age, Pace, Jockey, Trainer, SP Fav, Industry SP, Pred ISP, Place, Winning Distance, Runners, Runs last 18 mo, LTO5 % SP Drop, LTO4 % SP Drop, LTO3 % SP Drop, LTO2 % SP Drop, LTO % SP Drop, LTO5 IPL, LTO4 IPL, LTO3 IPL, LTO2 IPL, LTO IPL, Wins L5, Avg % SP Drop L5, Avg % SP Drop last 18 mo, Prev Races, Days Since LTO, Cla diff since LTO, OR diff since LTO, Crs Wins, Dist Wins, Class Wins, Going Wins, Dist (F), WGT (Lbs), WGT diff since LTO, LTO Pos, OR, Headgear, Country_IRE, Track_ASCOT, Track_AYR, Track_BALLINROBE, Track_BANGOR-ON-DEE, Track_BATH, Track_BELLEWSTOWN, Track_BEVERLEY, Track_BRIGHTON, Track_CARLISLE, Track_CARTMEL, Track_CATTERICK, Track_CHELMSFORD CITY, Track_CHELTENHAM, Track_CHEPSTOW, Track_CHESTER, Track_CLONMEL, Track_CORK, Track_CURRAGH, Track_DONCASTER, Track_DOWN ROYAL, Track_DOWNPATRICK, Track_DUNDALK, Track_EPSOM, Track_EXETER, Track_FAIRYHOUSE, Track_FAKENHAM, Track_FFOS LAS, Track_FONTWELL, Track_GALWAY, Track_GOODWOOD, Track_GOWRAN PARK, Track_HAMILTON, Track_HAYDOCK, Track_HEREFORD, Track_HEXHAM, Track_HUNTINGDON, Track_KELSO, Track_KEMPTON, Track_KILBEGGAN, Track_KILLARNEY, Track_LAYTOWN, Track_LEICESTER, Track_LEOPARDSTOWN, Track_LIMERICK, Track_LINGFIELD, Track_LISTOWEL, Track_LUDLOW, Track_MARKET RASEN, Track_MUSSELBURGH, Track_NAAS, Track_NAVAN, Track_NEWBURY, Track_NEWCASTLE, Track_NEWMARKET, Track_NEWTON ABBOT, Track_NOTTINGHAM, Track_PERTH, Track_PLUMPTON, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 227 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Identify rows with invalid dates\n",
    "invalid_dates = df_cleaned[df_cleaned['Date'].isna()]\n",
    "\n",
    "# Print the rows with invalid date formats\n",
    "print(invalid_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is your original DataFrame\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Create two DataFrames based on the date\n",
    "df_date_04112024 = df_cleaned[df_cleaned['Date'] == '2024-11-04']\n",
    "df_other_dates = df_cleaned[df_cleaned['Date'] != '2024-11-04']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 227)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date_04112024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58019, 227)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_past = df_other_dates.drop(columns=['Date'])\n",
    "df_today = df_date_04112024.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Place' column: [  2   5   1  12  23  11   6  14   8   3  15   7  21   4  10  19   9  16\n",
      "  20  13  18  27  24  -1  -2  28  -3  17  -4  26  -5  -6  22  25  29  31\n",
      "  -7  -8  30  -9 -10]\n"
     ]
    }
   ],
   "source": [
    "# Print unique values in the 'Place' column\n",
    "unique_places = df_past[\"Place\"].unique()\n",
    "print(\"Unique values in 'Place' column:\", unique_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 328 entries, 31265 to 38133\n",
      "Columns: 226 entries, Class to Up in Trip_YES\n",
      "dtypes: bool(186), float64(22), int64(18)\n",
      "memory usage: 164.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_today.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 58019 entries, 0 to 58346\n",
      "Columns: 226 entries, Class to Up in Trip_YES\n",
      "dtypes: bool(186), float64(22), int64(18)\n",
      "memory usage: 28.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_past.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Place']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in df_past.columns if \"Place\" in col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Jockey</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>SP Fav</th>\n",
       "      <th>Industry SP</th>\n",
       "      <th>Pred ISP</th>\n",
       "      <th>Place</th>\n",
       "      <th>...</th>\n",
       "      <th>Distance_4m½f</th>\n",
       "      <th>Distance_5f</th>\n",
       "      <th>Distance_5½f</th>\n",
       "      <th>Distance_6f</th>\n",
       "      <th>Distance_6½f</th>\n",
       "      <th>Distance_7f</th>\n",
       "      <th>Distance_7½f</th>\n",
       "      <th>Course Winner_YES</th>\n",
       "      <th>Distance Winner_YES</th>\n",
       "      <th>Up in Trip_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31265</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1043</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class  Horse  Age  Pace  Jockey  Trainer  SP Fav  Industry SP  \\\n",
       "31265    6.0      4    2   4.0    1043      434       1          4.0   \n",
       "\n",
       "       Pred ISP  Place  ...  Distance_4m½f  Distance_5f  Distance_5½f  \\\n",
       "31265       4.0      1  ...          False        False         False   \n",
       "\n",
       "       Distance_6f  Distance_6½f  Distance_7f  Distance_7½f  \\\n",
       "31265        False         False         True         False   \n",
       "\n",
       "       Course Winner_YES  Distance Winner_YES  Up in Trip_YES  \n",
       "31265              False                False            True  \n",
       "\n",
       "[1 rows x 226 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_today.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8709927611168563\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      6911\n",
      "           1       0.85      0.83      0.84      4693\n",
      "\n",
      "    accuracy                           0.87     11604\n",
      "   macro avg       0.87      0.86      0.87     11604\n",
      "weighted avg       0.87      0.87      0.87     11604\n",
      "\n",
      "ROC-AUC Score: 0.9419696834641335\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "             Feature  Importance\n",
      "9   Winning Distance         976\n",
      "4             Jockey         540\n",
      "7        Industry SP         473\n",
      "1              Horse         459\n",
      "5            Trainer         437\n",
      "26    Days Since LTO         396\n",
      "33          Dist (F)         391\n",
      "10           Runners         391\n",
      "16     LTO % SP Drop         373\n",
      "34         WGT (Lbs)         352\n",
      "\n",
      "Sample of df_today_with_top3_predictions:\n",
      "  Place          Track           Horse              Jockey         Racetype  \\\n",
      "0     1      SOUTHWELL   A Fine Claret  Pierre-Louis Jamin          Nursery   \n",
      "1     1  WOLVERHAMPTON  A Pint Of Bear         Joey Haynes   Other Handicap   \n",
      "2     1        KEMPTON    Africa Charm         Neil Callan           Maiden   \n",
      "3     1       PLUMPTON         Aggagio       Caoilin Quinn  Handicap Hurdle   \n",
      "4     1        KEMPTON         Aimeric        Clifford Lee           Listed   \n",
      "\n",
      "    Time  Top3  Probability_Top3  \n",
      "0  17:45     1          0.937998  \n",
      "1  18:00     1          0.867276  \n",
      "2  13:20     1          0.924429  \n",
      "3  15:40     0          0.664368  \n",
      "4  14:20     1          0.945785  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Transform the Place column into a binary target\n",
    "df_past[\"Top3\"] = df_past[\"Place\"].apply(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "df_today[\"Top3\"] = None  # Placeholder for predictions\n",
    "\n",
    "# Define features and target\n",
    "X_past = df_past.drop(columns=[\"Place\", \"Top3\"])\n",
    "y_past = df_past[\"Top3\"]\n",
    "\n",
    "X_today = df_today.drop(columns=[\"Place\", \"Top3\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_past, y_past, test_size=0.2, random_state=42, stratify=y_past)\n",
    "\n",
    "# Hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    \"num_leaves\": [15, 31, 63],\n",
    "    \"max_depth\": [-1, 10, 20],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"min_child_samples\": [10, 20, 30],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize LightGBM binary classifier\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning (uncomment to perform grid search)\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=lgbm,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring=\"roc_auc\",\n",
    "#     cv=3,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters (from GridSearchCV or manually set)\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'n_estimators': 200,\n",
    "    'num_leaves': 63,\n",
    "    'subsample': 0.7\n",
    "}\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = lgb.LGBMClassifier(random_state=42, **best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "y_pred_proba_test = final_model.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "# Metrics\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba_test))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": final_model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Predict for df_today\n",
    "df_today[\"Top3\"] = final_model.predict(X_today)\n",
    "df_today[\"Probability_Top3\"] = final_model.predict_proba(X_today)[:, 1]  # Probability of being in Top 3\n",
    "\n",
    "# Adjust the Top3 predictions based on the probability threshold of 0.75\n",
    "df_today[\"Top3\"] = df_today.apply(\n",
    "    lambda row: 1 if row[\"Probability_Top3\"] >= 0.75 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Combine df_aux with prediction and probability columns\n",
    "df_today_with_predictions = pd.concat(\n",
    "    [df_aux.reset_index(drop=True), df_today[[\"Top3\", \"Probability_Top3\"]].reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "df_today_with_predictions.to_csv(\"df_today_with_top3_predictions.csv\", index=False)\n",
    "\n",
    "# Display a sample of the combined DataFrame\n",
    "print(\"\\nSample of df_today_with_top3_predictions:\")\n",
    "print(df_today_with_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Horse ID' column is missing!\n"
     ]
    }
   ],
   "source": [
    "if 'Horse ID' in df_today.columns:\n",
    "    print(\"'Horse ID' column exists in df_today\")\n",
    "else:\n",
    "    print(\"'Horse ID' column is missing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded results_df columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 95 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Date               317 non-null    object \n",
      " 1   Place              317 non-null    object \n",
      " 2   BFSP Rank          317 non-null    int64  \n",
      " 3   Ind SP             317 non-null    object \n",
      " 4   Ind SP Decimal     317 non-null    float64\n",
      " 5   Time               317 non-null    object \n",
      " 6   Runners            317 non-null    int64  \n",
      " 7   Track Name         317 non-null    object \n",
      " 8   Class (GB only)    317 non-null    int64  \n",
      " 9   Distance           317 non-null    object \n",
      " 10  Age                317 non-null    int64  \n",
      " 11  Horse              317 non-null    object \n",
      " 12  Weight             317 non-null    object \n",
      " 13  Trainer            317 non-null    object \n",
      " 14  Jockey             317 non-null    object \n",
      " 15  OffR               263 non-null    float64\n",
      " 16  Race Name          317 non-null    object \n",
      " 17  Going              317 non-null    object \n",
      " 18  Headgear           134 non-null    object \n",
      " 19  WinDist            269 non-null    object \n",
      " 20  Min Price          317 non-null    float64\n",
      " 21  Max Price          317 non-null    float64\n",
      " 22  Silk No            317 non-null    int64  \n",
      " 23  Pace               317 non-null    int64  \n",
      " 24  Stall / Draw       235 non-null    float64\n",
      " 25  Winning Time       317 non-null    object \n",
      " 26  Prize Money        317 non-null    float64\n",
      " 27  BSP                317 non-null    float64\n",
      " 28  15 Mins            317 non-null    float64\n",
      " 29  10 mins            317 non-null    object \n",
      " 30  5 mins             311 non-null    float64\n",
      " 31  3 mins             317 non-null    float64\n",
      " 32  2 mins             317 non-null    float64\n",
      " 33  1 min              317 non-null    float64\n",
      " 34  Post Time          317 non-null    float64\n",
      " 35  Last Traded Price  317 non-null    float64\n",
      " 36  Unnamed: 36        317 non-null    float64\n",
      " 37  Unnamed: 37        317 non-null    float64\n",
      " 38  Unnamed: 38        317 non-null    float64\n",
      " 39  Unnamed: 39        317 non-null    float64\n",
      " 40  Unnamed: 40        317 non-null    float64\n",
      " 41  Unnamed: 41        317 non-null    float64\n",
      " 42  Unnamed: 42        317 non-null    float64\n",
      " 43  Unnamed: 43        317 non-null    float64\n",
      " 44  Unnamed: 44        307 non-null    float64\n",
      " 45  Unnamed: 45        301 non-null    float64\n",
      " 46  Unnamed: 46        301 non-null    float64\n",
      " 47  Unnamed: 47        290 non-null    float64\n",
      " 48  Unnamed: 48        272 non-null    float64\n",
      " 49  Unnamed: 49        264 non-null    float64\n",
      " 50  Unnamed: 50        264 non-null    float64\n",
      " 51  Unnamed: 51        241 non-null    float64\n",
      " 52  Unnamed: 52        219 non-null    float64\n",
      " 53  Unnamed: 53        209 non-null    float64\n",
      " 54  Unnamed: 54        189 non-null    float64\n",
      " 55  Unnamed: 55        157 non-null    float64\n",
      " 56  Unnamed: 56        157 non-null    float64\n",
      " 57  Unnamed: 57        157 non-null    float64\n",
      " 58  Unnamed: 58        157 non-null    float64\n",
      " 59  Unnamed: 59        145 non-null    float64\n",
      " 60  Unnamed: 60        135 non-null    float64\n",
      " 61  Unnamed: 61        135 non-null    float64\n",
      " 62  Unnamed: 62        135 non-null    float64\n",
      " 63  Unnamed: 63        121 non-null    float64\n",
      " 64  Unnamed: 64        114 non-null    float64\n",
      " 65  Unnamed: 65        104 non-null    float64\n",
      " 66  Unnamed: 66        104 non-null    float64\n",
      " 67  Unnamed: 67        104 non-null    float64\n",
      " 68  Unnamed: 68        96 non-null     float64\n",
      " 69  Unnamed: 69        90 non-null     float64\n",
      " 70  Unnamed: 70        90 non-null     float64\n",
      " 71  Unnamed: 71        78 non-null     float64\n",
      " 72  Unnamed: 72        71 non-null     float64\n",
      " 73  Unnamed: 73        71 non-null     float64\n",
      " 74  Unnamed: 74        71 non-null     float64\n",
      " 75  Unnamed: 75        68 non-null     float64\n",
      " 76  Unnamed: 76        68 non-null     float64\n",
      " 77  Unnamed: 77        55 non-null     float64\n",
      " 78  Unnamed: 78        55 non-null     float64\n",
      " 79  Unnamed: 79        48 non-null     float64\n",
      " 80  Unnamed: 80        48 non-null     float64\n",
      " 81  Unnamed: 81        31 non-null     float64\n",
      " 82  Unnamed: 82        31 non-null     float64\n",
      " 83  Unnamed: 83        31 non-null     float64\n",
      " 84  Unnamed: 84        31 non-null     float64\n",
      " 85  Unnamed: 85        31 non-null     float64\n",
      " 86  Unnamed: 86        31 non-null     float64\n",
      " 87  Unnamed: 87        31 non-null     float64\n",
      " 88  Unnamed: 88        31 non-null     float64\n",
      " 89  Unnamed: 89        24 non-null     float64\n",
      " 90  Unnamed: 90        24 non-null     float64\n",
      " 91  Unnamed: 91        16 non-null     float64\n",
      " 92  Unnamed: 92        12 non-null     float64\n",
      " 93  Unnamed: 93        12 non-null     float64\n",
      " 94  Unnamed: 94        6 non-null      float64\n",
      "dtypes: float64(73), int64(6), object(16)\n",
      "memory usage: 235.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "results_file_path = '/Users/rishabh/Downloads/Results - 04112024 (1).csv'\n",
    "results_df = pd.read_csv(results_file_path)\n",
    "print(\"Reloaded results_df columns:\")\n",
    "print(results_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in results_df:\n",
      "Index(['Date', 'Place', 'BFSP Rank', 'Ind SP', 'Ind SP Decimal', 'Time',\n",
      "       'Runners', 'Track Name', 'Class (GB only)', 'Distance', 'Age', 'Horse',\n",
      "       'Weight', 'Trainer', 'Jockey', 'OffR', 'Race Name', 'Going', 'Headgear',\n",
      "       'WinDist', 'Min Price', 'Max Price', 'Silk No', 'Pace', 'Stall / Draw',\n",
      "       'Winning Time', 'Prize Money', 'BSP', '15 Mins', '10 mins', '5 mins',\n",
      "       '3 mins', '2 mins', '1 min ', 'Post Time', 'Last Traded Price',\n",
      "       'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39',\n",
      "       'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43',\n",
      "       'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47',\n",
      "       'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51',\n",
      "       'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55',\n",
      "       'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59',\n",
      "       'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63',\n",
      "       'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67',\n",
      "       'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71',\n",
      "       'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75',\n",
      "       'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79',\n",
      "       'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83',\n",
      "       'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87',\n",
      "       'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91',\n",
      "       'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in df_today:\n",
      "['Class', 'Horse', 'Age', 'Pace', 'Jockey', 'Trainer', 'SP Fav', 'Industry SP', 'Pred ISP', 'Place', 'Winning Distance', 'Runners', 'Runs last 18 mo', 'LTO5 % SP Drop', 'LTO4 % SP Drop', 'LTO3 % SP Drop', 'LTO2 % SP Drop', 'LTO % SP Drop', 'LTO5 IPL', 'LTO4 IPL', 'LTO3 IPL', 'LTO2 IPL', 'LTO IPL', 'Wins L5', 'Avg % SP Drop L5', 'Avg % SP Drop last 18 mo', 'Prev Races', 'Days Since LTO', 'Cla diff since LTO', 'OR diff since LTO', 'Crs Wins', 'Dist Wins', 'Class Wins', 'Going Wins', 'Dist (F)', 'WGT (Lbs)', 'WGT diff since LTO', 'LTO Pos', 'OR', 'Headgear', 'Country_IRE', 'Track_ASCOT', 'Track_AYR', 'Track_BALLINROBE', 'Track_BANGOR-ON-DEE', 'Track_BATH', 'Track_BELLEWSTOWN', 'Track_BEVERLEY', 'Track_BRIGHTON', 'Track_CARLISLE', 'Track_CARTMEL', 'Track_CATTERICK', 'Track_CHELMSFORD CITY', 'Track_CHELTENHAM', 'Track_CHEPSTOW', 'Track_CHESTER', 'Track_CLONMEL', 'Track_CORK', 'Track_CURRAGH', 'Track_DONCASTER', 'Track_DOWN ROYAL', 'Track_DOWNPATRICK', 'Track_DUNDALK', 'Track_EPSOM', 'Track_EXETER', 'Track_FAIRYHOUSE', 'Track_FAKENHAM', 'Track_FFOS LAS', 'Track_FONTWELL', 'Track_GALWAY', 'Track_GOODWOOD', 'Track_GOWRAN PARK', 'Track_HAMILTON', 'Track_HAYDOCK', 'Track_HEREFORD', 'Track_HEXHAM', 'Track_HUNTINGDON', 'Track_KELSO', 'Track_KEMPTON', 'Track_KILBEGGAN', 'Track_KILLARNEY', 'Track_LAYTOWN', 'Track_LEICESTER', 'Track_LEOPARDSTOWN', 'Track_LIMERICK', 'Track_LINGFIELD', 'Track_LISTOWEL', 'Track_LUDLOW', 'Track_MARKET RASEN', 'Track_MUSSELBURGH', 'Track_NAAS', 'Track_NAVAN', 'Track_NEWBURY', 'Track_NEWCASTLE', 'Track_NEWMARKET', 'Track_NEWTON ABBOT', 'Track_NOTTINGHAM', 'Track_PERTH', 'Track_PLUMPTON', 'Track_PONTEFRACT', 'Track_PUNCHESTOWN', 'Track_REDCAR', 'Track_RIPON', 'Track_ROSCOMMON', 'Track_SALISBURY', 'Track_SANDOWN', 'Track_SEDGEFIELD', 'Track_SLIGO', 'Track_SOUTHWELL', 'Track_STRATFORD', 'Track_TAUNTON', 'Track_THIRSK', 'Track_THURLES', 'Track_TIPPERARY', 'Track_TOWCESTER', 'Track_TRAMORE', 'Track_UTTOXETER', 'Track_WARWICK', 'Track_WETHERBY', 'Track_WEXFORD', 'Track_WINCANTON', 'Track_WINDSOR', 'Track_WOLVERHAMPTON', 'Track_WORCESTER', 'Track_YARMOUTH', 'Track_YORK', 'Going_GD', 'Going_GTF', 'Going_GTS', 'Going_GTY', 'Going_HTS', 'Going_HVY', 'Going_SFT', 'Going_SLW', 'Going_STD', 'Going_STFA', 'Going_STSL', 'Going_YLD', 'Going_YTS', 'Racetype_Claiming Stakes', 'Racetype_Classified Stakes', 'Racetype_Conditions Stakes', 'Racetype_Group 1', 'Racetype_Group 2', 'Racetype_Group 3', 'Racetype_Handicap Chase', 'Racetype_Handicap Hurdle', 'Racetype_Hunters Chase', 'Racetype_Listed', 'Racetype_Maiden', 'Racetype_NH Flat', 'Racetype_Novice Chase', 'Racetype_Novice Hcap Chase', 'Racetype_Novice Hcap Hurdle', 'Racetype_Novice Hurdle', 'Racetype_Novice Stakes', 'Racetype_Nursery', 'Racetype_Other Chase', 'Racetype_Other Handicap', 'Racetype_Other Hurdle', 'Racetype_Selling Handicap', 'Racetype_Selling Hurdle', 'Racetype_Selling Stakes', 'Racetype_Unclassified', 'Distance_1m1f', 'Distance_1m1½f', 'Distance_1m2f', 'Distance_1m2½f', 'Distance_1m3f', 'Distance_1m3½f', 'Distance_1m4f', 'Distance_1m4½f', 'Distance_1m5f', 'Distance_1m5½f', 'Distance_1m6f', 'Distance_1m6½f', 'Distance_1m7f', 'Distance_1m7½f', 'Distance_1m½f', 'Distance_2m', 'Distance_2m1f', 'Distance_2m1½f', 'Distance_2m2f', 'Distance_2m2½f', 'Distance_2m3f', 'Distance_2m3½f', 'Distance_2m4f', 'Distance_2m4½f', 'Distance_2m5f', 'Distance_2m5½f', 'Distance_2m6f', 'Distance_2m6½f', 'Distance_2m7f', 'Distance_2m7½f', 'Distance_2m½f', 'Distance_3m', 'Distance_3m1f', 'Distance_3m1½f', 'Distance_3m2f', 'Distance_3m2½f', 'Distance_3m3f', 'Distance_3m3½f', 'Distance_3m4f', 'Distance_3m4½f', 'Distance_3m5f', 'Distance_3m5½f', 'Distance_3m6f', 'Distance_3m6½f', 'Distance_3m7f', 'Distance_3m7½f', 'Distance_3m½f', 'Distance_4m', 'Distance_4m1f', 'Distance_4m1½f', 'Distance_4m2f', 'Distance_4m2½f', 'Distance_4m½f', 'Distance_5f', 'Distance_5½f', 'Distance_6f', 'Distance_6½f', 'Distance_7f', 'Distance_7½f', 'Course Winner_YES', 'Distance Winner_YES', 'Up in Trip_YES', 'Top3']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in results_df:\")\n",
    "print(results_df.columns)\n",
    "\n",
    "print(\"\\nColumns in df_today:\")\n",
    "print(df_today.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract track columns (start with \"Track_\")\n",
    "track_columns = [col for col in df_today.columns if col.startswith('Track_')]\n",
    "\n",
    "# Convert one-hot columns to a single \"Track\" column\n",
    "df_today['Track'] = df_today[track_columns].idxmax(axis=1).str.replace('Track_', '')\n",
    "\n",
    "# Drop the one-hot columns if no longer needed\n",
    "df_today = df_today.drop(columns=track_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tracks in df_today: ['SOUTHWELL' 'WOLVERHAMPTON' 'KEMPTON' 'PLUMPTON' 'HEREFORD']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Track'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Track'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique tracks in df_today:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_today[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrack\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique tracks in results_df:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Track'"
     ]
    }
   ],
   "source": [
    "print(\"Unique tracks in df_today:\", df_today['Track'].unique())\n",
    "print(\"Unique tracks in results_df:\", results_df['Track'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Composite Key'] = (\n",
    "    results_df['Track'].astype(str) + \"_\" +\n",
    "    results_df['Horse'].astype(str)\n",
    ")\n",
    "\n",
    "df_today['Composite Key'] = (\n",
    "    df_today['Track'].astype(str) + \"_\" +\n",
    "    df_today['Horse'].astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    df_today,\n",
    "    results_df[['Composite Key', 'Place']],\n",
    "    on='Composite Key',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Track  Horse  Place_x\n",
      "0      SOUTHWELL      4        1\n",
      "1  WOLVERHAMPTON      9        1\n",
      "2        KEMPTON     31        1\n",
      "3       PLUMPTON     36        1\n",
      "4        KEMPTON     42        1\n",
      "           Track  Horse Place_y\n",
      "0      SOUTHWELL      4     NaN\n",
      "1  WOLVERHAMPTON      9     NaN\n",
      "2        KEMPTON     31     NaN\n",
      "3       PLUMPTON     36     NaN\n",
      "4        KEMPTON     42     NaN\n"
     ]
    }
   ],
   "source": [
    "print(merged_df[['Track', 'Horse', 'Place_x']].head())\n",
    "print(merged_df[['Track', 'Horse', 'Place_y']].head())  # If Place_y exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabh/opt/anaconda3/envs/tfenv/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8658221302998966\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      6911\n",
      "           1       0.84      0.82      0.83      4693\n",
      "\n",
      "    accuracy                           0.87     11604\n",
      "   macro avg       0.86      0.86      0.86     11604\n",
      "weighted avg       0.87      0.87      0.87     11604\n",
      "\n",
      "ROC-AUC Score: 0.9373495586622438\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "                     Feature  Importance\n",
      "9           Winning Distance    0.119074\n",
      "157  Racetype_Other Handicap    0.042278\n",
      "6                     SP Fav    0.027780\n",
      "33                  Dist (F)    0.027148\n",
      "56                Track_CORK    0.017246\n",
      "10                   Runners    0.012716\n",
      "7                Industry SP    0.012191\n",
      "68              Track_GALWAY    0.012139\n",
      "137                Going_YTS    0.011226\n",
      "73            Track_HEREFORD    0.009854\n",
      "Sample Predictions for Top 3 Finishes:\n",
      "       Top3\n",
      "31265     1\n",
      "31312     1\n",
      "31314     1\n",
      "31345     1\n",
      "31362     1\n",
      "\n",
      "Predictions saved to 'df_today_with_top3_predictions_xgb.csv'\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialize XGBoost binary classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test)[:, 1]  # For ROC-AUC\n",
    "\n",
    "# Metrics\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba_test))\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": xgb_model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Predict for df_today\n",
    "df_today[\"Top3\"] = xgb_model.predict(X_today)\n",
    "\n",
    "# Display predictions alongside other columns\n",
    "print(\"Sample Predictions for Top 3 Finishes:\")\n",
    "print(df_today[[\"Top3\"]].head())\n",
    "\n",
    "# Save predictions to a CSV file (optional)\n",
    "df_today.to_csv(\"df_today_with_top3_predictions_xgb.csv\", index=False)\n",
    "print(\"\\nPredictions saved to 'df_today_with_top3_predictions_xgb.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.843329886246122\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      6556\n",
      "           1       0.80      0.85      0.83      5048\n",
      "\n",
      "    accuracy                           0.84     11604\n",
      "   macro avg       0.84      0.84      0.84     11604\n",
      "weighted avg       0.85      0.84      0.84     11604\n",
      "\n",
      "Test ROC-AUC Score: 0.9229543121844812\n",
      "\n",
      "Sample Predictions for df_today:\n",
      "       Horse  Top3_Predicted  Top3_Probability\n",
      "31265      4               1          0.841030\n",
      "31312      9               1          0.657879\n",
      "31314     31               1          0.519410\n",
      "31345     36               1          0.960282\n",
      "31362     42               1          0.740272\n",
      "\n",
      "Predictions saved to 'df_today_with_top3_predictions_svm.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convert 'Place' to binary (Top 3 -> 1, Else -> 0)\n",
    "df_past[\"Top3\"] = (df_past[\"Place\"] <= 3).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "X = df_past.drop(columns=[\"Place\", \"Top3\"])\n",
    "y = df_past[\"Top3\"]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = svm_model.predict(X_test)\n",
    "y_pred_proba_test = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# ROC-AUC Score\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "print(\"Test ROC-AUC Score:\", test_auc)\n",
    "\n",
    "# Predict for df_today\n",
    "df_today_scaled = scaler.transform(df_today.drop(columns=[\"Place\"]))\n",
    "df_today[\"Top3_Predicted\"] = svm_model.predict(df_today_scaled)\n",
    "df_today[\"Top3_Probability\"] = svm_model.predict_proba(df_today_scaled)[:, 1]\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions for df_today:\")\n",
    "print(df_today[[\"Horse\", \"Top3_Predicted\", \"Top3_Probability\"]].head())\n",
    "\n",
    "# Save predictions to a CSV file (optional)\n",
    "df_today.to_csv(\"df_today_with_top3_predictions_svm.csv\", index=False)\n",
    "print(\"\\nPredictions saved to 'df_today_with_top3_predictions_svm.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "df_past[\"Top3\"] = (df_past[\"Place\"]<=3).astype(int)\n",
    "\n",
    "X = df_past.drop(columns = \"Top3\", \"Place\")\n",
    "y = df_past[\"Top3\"]\\\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_split = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation = 'relu', input_shape=(X_train[1].shape,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_cross_entropy',metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
